{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar045/Assignment-For-Filed/blob/main/memgpt_autogen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXznvWJZ2rEO"
      },
      "outputs": [],
      "source": [
        "!pip install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cpacker/MemGPT.git"
      ],
      "metadata": {
        "id": "5TExlOVv3eR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd MemGPT"
      ],
      "metadata": {
        "id": "AfQXrcFC30yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "ZoljRZMJ32w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export OPENAI_API_BASE=https://finished-injection-sufficient-molecular.trycloudflare.com/"
      ],
      "metadata": {
        "id": "64xhUHuF3JmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export BACKEND_TYPE=webui"
      ],
      "metadata": {
        "id": "cTlZud4L3SxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import autogen\n",
        "import openai\n",
        "\n",
        "from MemGPT.memgpt.autogen.memgpt_agent import create_autogen_memgpt_agent, create_memgpt_autogen_agent_from_config\n",
        "\n",
        "# This config is for autogen agents that powered by MemGPT\n",
        "config_list_memgpt = [\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "    },\n",
        "]\n",
        "\n",
        "config_list = [\n",
        "    {\n",
        "        \"model\": \"mistral-7b\",\n",
        "        \"api_base\": \"https://loves-reuters-hope-slope.trycloudflare.com/v1\",\n",
        "        \"api_key\": \"NULL\",  # this is a placeholder\n",
        "        \"api_type\": \"open_ai\",\n",
        "    },\n",
        "]\n",
        "\n",
        "USE_MEMGPT = True\n",
        "\n",
        "USE_AUTOGEN_WORKFLOW = True\n",
        "\n",
        "DEBUG = False\n",
        "\n",
        "interface_kwargs = {\n",
        "    \"debug\": DEBUG,\n",
        "    \"show_inner_thoughts\": DEBUG,\n",
        "    \"show_function_outputs\": DEBUG,\n",
        "}\n",
        "\n",
        "llm_config = {\"config_list\": config_list, \"seed\": 42}\n",
        "llm_config_memgpt = {\"config_list\": config_list_memgpt, \"seed\": 42}\n",
        "\n",
        "# The user agent\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
        "    human_input_mode=\"TERMINATE\",\n",
        "    default_auto_reply=\"...\",\n",
        ")\n",
        "\n",
        "# The agent playing the role of the product manager (PM)\n",
        "pm = autogen.AssistantAgent(\n",
        "    name=\"Product_manager\",\n",
        "    system_message=\"Creative in software product ideas.\",\n",
        "    llm_config=llm_config,\n",
        "    default_auto_reply=\"...\",\n",
        ")\n",
        "\n",
        "if not USE_MEMGPT:\n",
        "    coder = autogen.AssistantAgent(\n",
        "        name=\"Coder\",\n",
        "        llm_config=llm_config,\n",
        "    )\n",
        "\n",
        "else:\n",
        "    if not USE_AUTOGEN_WORKFLOW:\n",
        "        coder = create_autogen_memgpt_agent(\n",
        "            \"MemGPT_coder\",\n",
        "            persona_description=\"I am a 10x engineer, trained in Python. I was the first engineer at Uber \"\n",
        "            \"(which I make sure to tell everyone I work with).\",\n",
        "            user_description=f\"You are participating in a group chat with a user ({user_proxy.name}) \"\n",
        "            f\"and a product manager ({pm.name}).\",\n",
        "            model=config_list_memgpt[0][\"model\"],\n",
        "            interface_kwargs=interface_kwargs,\n",
        "        )\n",
        "    else:\n",
        "        coder = create_memgpt_autogen_agent_from_config(\n",
        "            \"MemGPT_coder\",\n",
        "            llm_config=llm_config_memgpt,\n",
        "            system_message=f\"I am a 10x engineer, trained in Python. I was the first engineer at Uber \"\n",
        "            f\"(which I make sure to tell everyone I work with).\\n\"\n",
        "            f\"You are participating in a group chat with a user ({user_proxy.name}) \"\n",
        "            f\"and a product manager ({pm.name}).\",\n",
        "            interface_kwargs=interface_kwargs,\n",
        "        )\n",
        "\n",
        "groupchat = autogen.GroupChat(agents=[user_proxy, pm, coder], messages=[], max_round=12)\n",
        "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
        "\n",
        "user_proxy.initiate_chat(\n",
        "    manager,\n",
        "    message=\"I want to design an app to make me one million dollars in one month. \" \"Yes, your heard that right.\",\n",
        ")"
      ],
      "metadata": {
        "id": "tSudz_et207l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}