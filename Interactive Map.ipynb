{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH7C98Hr9yhqt4N2tl0hHO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumar045/Assignment-For-Filed/blob/main/Interactive%20Map.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Displaying country name based on finger placement.\n",
        "Place your finger on a country and it will tell you its name.\n",
        "\n",
        "**Author:** Murtaza Hassan\n",
        "**Website:** www.computervision.zone\n",
        "\n",
        "\"\"\"\n",
        "# Import necessary libraries\n",
        "import pickle  # Pickle library for serializing Python objects\n",
        "import cv2  # OpenCV library for computer vision tasks\n",
        "import cvzone\n",
        "import numpy as np  # NumPy library for numerical operations\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "\n",
        "######################################\n",
        "cam_id = 4\n",
        "width, height = 1920, 1080\n",
        "map_file_path = \"../Step1_GetCornerPoints/map.p\"\n",
        "countries_file_path = \"../Step2_Get_Country_Polygons/countries.p\"\n",
        "######################################\n",
        "\n",
        "file_obj = open(map_file_path, 'rb')\n",
        "map_points = pickle.load(file_obj)\n",
        "file_obj.close()\n",
        "print(f\"Loaded map coordinates.\")\n",
        "\n",
        "# Load previously defined Regions of Interest (ROIs) polygons from a file\n",
        "if countries_file_path:\n",
        "    file_obj = open(countries_file_path, 'rb')\n",
        "    polygons = pickle.load(file_obj)\n",
        "    file_obj.close()\n",
        "    print(f\"Loaded {len(polygons)} countries.\")\n",
        "else:\n",
        "    polygons = []\n",
        "\n",
        "# Open a connection to the webcam\n",
        "cap = cv2.VideoCapture(cam_id)  # For Webcam\n",
        "# Set the width and height of the webcam frame\n",
        "cap.set(3, width)\n",
        "cap.set(4, height)\n",
        "# Counter to keep track of how many polygons have been created\n",
        "counter = 0\n",
        "\n",
        "# Initialize the HandDetector class with the given parameters\n",
        "detector = HandDetector(staticMode=False,\n",
        "                        maxHands=1,\n",
        "                        modelComplexity=1,\n",
        "                        detectionCon=0.5,\n",
        "                        minTrackCon=0.5)\n",
        "\n",
        "\n",
        "def warp_image(img, points, size=[1920, 1080]):\n",
        "    \"\"\"\n",
        "    Warp the input image based on the provided points to create a top-down view.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Input image.\n",
        "    - points: List of four points representing the region to be warped.\n",
        "    - size: Size of the output image.\n",
        "\n",
        "    Returns:\n",
        "    - imgOutput: Warped image.\n",
        "    - matrix: Transformation matrix.\n",
        "    \"\"\"\n",
        "    pts1 = np.float32([points[0], points[1], points[2], points[3]])\n",
        "    pts2 = np.float32([[0, 0], [size[0], 0], [0, size[1]], [size[0], size[1]]])\n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "    imgOutput = cv2.warpPerspective(img, matrix, (size[0], size[1]))\n",
        "    return imgOutput, matrix\n",
        "\n",
        "\n",
        "def warp_single_point(point, matrix):\n",
        "    \"\"\"\n",
        "    Warp a single point using the provided perspective transformation matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - point: Coordinates of the point to be warped.\n",
        "    - matrix: Perspective transformation matrix.\n",
        "\n",
        "    Returns:\n",
        "    - point_warped: Warped coordinates of the point.\n",
        "    \"\"\"\n",
        "    # Convert the point to homogeneous coordinates\n",
        "    point_homogeneous = np.array([[point[0], point[1], 1]], dtype=np.float32)\n",
        "\n",
        "    # Apply the perspective transformation to the point\n",
        "    point_homogeneous_transformed = np.dot(matrix, point_homogeneous.T).T\n",
        "\n",
        "    # Convert back to non-homogeneous coordinates\n",
        "    point_warped = point_homogeneous_transformed[0, :2] / point_homogeneous_transformed[0, 2]\n",
        "\n",
        "    return point_warped\n",
        "\n",
        "\n",
        "def get_finger_location(img, imgWarped):\n",
        "    \"\"\"\n",
        "    Get the location of the index finger tip in the warped image.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original\n",
        "\n",
        " image.\n",
        "\n",
        "    Returns:\n",
        "    - warped_point: Coordinates of the index finger tip in the warped image.\n",
        "    \"\"\"\n",
        "    # Find hands in the current frame\n",
        "    hands, img = detector.findHands(img, draw=False, flipType=True)\n",
        "    # Check if any hands are detected\n",
        "    if hands:\n",
        "        # Information for the first hand detected\n",
        "        hand1 = hands[0]  # Get the first hand detected\n",
        "        indexFinger = hand1[\"lmList\"][8][0:2]  # List of 21 landmarks for the first hand\n",
        "        # cv2.circle(img,indexFinger,5,(255,0,255),cv2.FILLED)\n",
        "        warped_point = warp_single_point(indexFinger, matrix)\n",
        "        warped_point = int(warped_point[0]), int(warped_point[1])\n",
        "        print(indexFinger, warped_point)\n",
        "        cv2.circle(imgWarped, warped_point, 5, (255, 0, 0), cv2.FILLED)\n",
        "    else:\n",
        "        warped_point = None\n",
        "\n",
        "    return warped_point\n",
        "\n",
        "\n",
        "def create_overlay_image(polygons, warped_point, imgOverlay):\n",
        "    \"\"\"\n",
        "    Create an overlay image with marked polygons based on the warped finger location.\n",
        "\n",
        "    Parameters:\n",
        "    - polygons: List of polygons representing countries.\n",
        "    - warped_point: Coordinates of the index finger tip in the warped image.\n",
        "    - imgOverlay: Overlay image to be marked.\n",
        "\n",
        "    Returns:\n",
        "    - imgOverlay: Overlay image with marked polygons.\n",
        "    \"\"\"\n",
        "    # loop through all the countries\n",
        "    for polygon, name in polygons:\n",
        "        polygon_np = np.array(polygon, np.int32).reshape((-1, 1, 2))\n",
        "        result = cv2.pointPolygonTest(polygon_np, warped_point, False)\n",
        "        if result >= 0:\n",
        "            cv2.polylines(imgOverlay, [np.array(polygon)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "            cv2.fillPoly(imgOverlay, [np.array(polygon)], (0, 255, 0))\n",
        "            cvzone.putTextRect(imgOverlay, name, polygon[0], scale=1, thickness=1)\n",
        "            cvzone.putTextRect(imgOverlay, name, (0, 100), scale=8, thickness=5)\n",
        "\n",
        "    return imgOverlay\n",
        "\n",
        "\n",
        "def inverse_warp_image(img, imgOverlay, map_points):\n",
        "    \"\"\"\n",
        "    Inverse warp an overlay image onto the original image using provided map points.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original image.\n",
        "    - imgOverlay: Overlay image to be warped.\n",
        "    - map_points: List of four points representing the region on the map.\n",
        "\n",
        "    Returns:\n",
        "    - result: Combined image with the overlay applied.\n",
        "    \"\"\"\n",
        "    # Convert map_points to NumPy array\n",
        "    map_points = np.array(map_points, dtype=np.float32)\n",
        "\n",
        "    # Define the destination points for the overlay image\n",
        "    destination_points = np.array([[0, 0], [imgOverlay.shape[1] - 1, 0], [0, imgOverlay.shape[0] - 1],\n",
        "                                   [imgOverlay.shape[1] - 1, imgOverlay.shape[0] - 1]], dtype=np.float32)\n",
        "\n",
        "    # Calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(destination_points, map_points)\n",
        "\n",
        "    # Warp the overlay image to fit the perspective of the original image\n",
        "    warped_overlay = cv2.warpPerspective(imgOverlay, M, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Combine the original image with the warped overlay\n",
        "    result = cv2.addWeighted(img, 1, warped_overlay, 0.65, 0, warped_overlay)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the webcam\n",
        "    success, img = cap.read()\n",
        "    imgWarped, matrix = warp_image(img, map_points)\n",
        "    imgOutput = img.copy()\n",
        "\n",
        "    # Find the hand and its landmarks\n",
        "    warped_point = get_finger_location(img, imgWarped)\n",
        "\n",
        "    h, w, _ = imgWarped.shape\n",
        "    imgOverlay = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "    if warped_point:\n",
        "        imgOverlay = create_overlay_image(polygons, warped_point, imgOverlay)\n",
        "        imgOutput = inverse_warp_image(img, imgOverlay, map_points)\n",
        "\n",
        "    # imgStacked = cvzone.stackImages([img, imgWarped,imgOutput,imgOverlay], 2, 0.3)\n",
        "    # cv2.imshow(\"Stacked Image\", imgStacked)\n",
        "\n",
        "    # cv2.imshow(\"Original Image\", img)\n",
        "    # cv2.imshow(\"Warped Image\", imgWarped)\n",
        "\n",
        "    cv2.imshow(\"Output Image\", imgOutput)\n",
        "    key = cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "tOC59_Uk_jbB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import pickle  # Pickle library for serializing Python objects\n",
        "import cv2  # OpenCV library for computer vision tasks\n",
        "import cvzone\n",
        "import numpy as np  # NumPy library for numerical operations\n",
        "from cvzone.HandTrackingModule import HandDetector\n",
        "\n",
        "######################################\n",
        "cam_id = 4\n",
        "width, height = 1920, 1080\n",
        "map_file_path = \"../Step1_GetCornerPoints/map.p\"\n",
        "countries_file_path = \"../Step2_Get_Country_Polygons/countries.p\"\n",
        "######################################\n",
        "\n",
        "file_obj = open(map_file_path, 'rb')\n",
        "map_points = pickle.load(file_obj)\n",
        "file_obj.close()\n",
        "print(f\"Loaded map coordinates.\")\n",
        "\n",
        "# Load previously defined Regions of Interest (ROIs) polygons from a file\n",
        "if countries_file_path:\n",
        "    file_obj = open(countries_file_path, 'rb')\n",
        "    polygons = pickle.load(file_obj)\n",
        "    file_obj.close()\n",
        "    print(f\"Loaded {len(polygons)} countries.\")\n",
        "else:\n",
        "    polygons = []\n",
        "\n",
        "# Open a connection to the webcam\n",
        "cap = cv2.VideoCapture(cam_id)  # For Webcam\n",
        "# Set the width and height of the webcam frame\n",
        "cap.set(3, width)\n",
        "cap.set(4, height)\n",
        "# Counter to keep track of how many polygons have been created\n",
        "counter = 0\n",
        "# Initialize the HandDetector class with the given parameters\n",
        "detector = HandDetector(staticMode=False,\n",
        "                        maxHands=2,\n",
        "                        modelComplexity=1,\n",
        "                        detectionCon=0.5,\n",
        "                        minTrackCon=0.5)\n",
        "\n",
        "flight_time_list = [[\"USA\", \"Australia\", \"19 hours\"],\n",
        "                    [\"USA\", \"Canada\", \"3 hours\"],\n",
        "                    [\"Australia\", \"India\", \"13 hours\"],\n",
        "                    [\"Australia\", \"Pakistan\", \"13 hours\"],\n",
        "                    [\"Saudi Arabia\", \"USA\", \"14 hours\"],\n",
        "                    ]\n",
        "\n",
        "\n",
        "\n",
        "def warp_image(img, points, size=[1920, 1080]):\n",
        "    \"\"\"\n",
        "    Warp the input image based on the provided points to create a top-down view.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Input image.\n",
        "    - points: List of four points representing the region to be warped.\n",
        "    - size: Size of the output image.\n",
        "\n",
        "    Returns:\n",
        "    - imgOutput: Warped image.\n",
        "    - matrix: Transformation matrix.\n",
        "    \"\"\"\n",
        "    pts1 = np.float32([points[0], points[1], points[2], points[3]])\n",
        "    pts2 = np.float32([[0, 0], [size[0], 0], [0, size[1]], [size[0], size[1]]])\n",
        "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
        "    imgOutput = cv2.warpPerspective(img, matrix, (size[0], size[1]))\n",
        "    return imgOutput, matrix\n",
        "\n",
        "\n",
        "def warp_single_point(point, matrix):\n",
        "    \"\"\"\n",
        "    Warp a single point using the provided perspective transformation matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - point: Coordinates of the point to be warped.\n",
        "    - matrix: Perspective transformation matrix.\n",
        "\n",
        "    Returns:\n",
        "    - point_warped: Warped coordinates of the point.\n",
        "    \"\"\"\n",
        "    # Convert the point to homogeneous coordinates\n",
        "    point_homogeneous = np.array([[point[0], point[1], 1]], dtype=np.float32)\n",
        "\n",
        "    # Apply the perspective transformation to the point\n",
        "    point_homogeneous_transformed = np.dot(matrix, point_homogeneous.T).T\n",
        "\n",
        "    # Convert back to non-homogeneous coordinates\n",
        "    point_warped = point_homogeneous_transformed[0, :2] / point_homogeneous_transformed[0, 2]\n",
        "    point_warped = int(point_warped[0]), int(point_warped[1])\n",
        "\n",
        "    return point_warped\n",
        "\n",
        "\n",
        "def inverse_warp_image(img, imgOverlay, map_points):\n",
        "    \"\"\"\n",
        "    Inverse warp an overlay image onto the original image using provided map points.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original image.\n",
        "    - imgOverlay: Overlay image to be warped.\n",
        "    - map_points: List of four points representing the region on the map.\n",
        "\n",
        "    Returns:\n",
        "    - result: Combined image with the overlay applied.\n",
        "    \"\"\"\n",
        "    # Convert map_points to NumPy array\n",
        "    map_points = np.array(map_points, dtype=np.float32)\n",
        "\n",
        "    # Define the destination points for the overlay image\n",
        "    destination_points = np.array([[0, 0], [imgOverlay.shape[1] - 1, 0], [0, imgOverlay.shape[0] - 1],\n",
        "                                   [imgOverlay.shape[1] - 1, imgOverlay.shape[0] - 1]], dtype=np.float32)\n",
        "\n",
        "    # Calculate the perspective transform matrix\n",
        "    M = cv2.getPerspectiveTransform(destination_points, map_points)\n",
        "\n",
        "    # Warp the overlay image to fit the perspective of the original image\n",
        "    warped_overlay = cv2.warpPerspective(imgOverlay, M, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    # Combine the original image with the warped overlay\n",
        "    result = cv2.addWeighted(img, 1, warped_overlay, 0.65, 0, warped_overlay)\n",
        "\n",
        "    return result\n",
        "\n",
        "def get_finger_location(img,imgWarped):\n",
        "    \"\"\"\n",
        "    Get the location of the index finger tip in the warped image.\n",
        "\n",
        "    Parameters:\n",
        "    - img: Original\n",
        "\n",
        " image.\n",
        "\n",
        "    Returns:\n",
        "    - warped_point: Coordinates of the index finger tip in the warped image.\n",
        "    \"\"\"\n",
        "    # Find hands in the current frame\n",
        "    hands, img = detector.findHands(img, draw=False, flipType=True)\n",
        "    # Check if any hands are detected\n",
        "    if hands:\n",
        "        # Information for the first hand detected\n",
        "        hand1 = hands[0]  # Get the first hand detected\n",
        "        indexFinger = hand1[\"lmList\"][8][0:2]  # List of 21 landmarks for the first hand\n",
        "        # cv2.circle(img,indexFinger,5,(255,0,255),cv2.FILLED)\n",
        "        warped_point = warp_single_point(indexFinger, matrix)\n",
        "        warped_point = int(warped_point[0]), int(warped_point[1])\n",
        "        print(indexFinger,warped_point)\n",
        "        cv2.circle(imgWarped, warped_point, 5, (255, 0, 0), cv2.FILLED)\n",
        "        if len(hands) == 2:\n",
        "            hand2 = hands[1]\n",
        "            indexFinger2 = hand2[\"lmList\"][8][0:2]  # List of 21 landmarks for the first hand\n",
        "            warped_point2 = warp_single_point(indexFinger2, matrix)\n",
        "            cv2.circle(imgWarped, warped_point2, 5, (255, 0, 255), cv2.FILLED)\n",
        "            warped_point = [warped_point, warped_point2]\n",
        "\n",
        "    else:\n",
        "        warped_point = None\n",
        "\n",
        "    return warped_point\n",
        "\n",
        "\n",
        "def create_overlay_image(polygons, warped_point, imgOverlay):\n",
        "    \"\"\"\n",
        "    Create an overlay image with marked polygons based on the warped finger location.\n",
        "\n",
        "    Parameters:\n",
        "    - polygons: List of polygons representing countries.\n",
        "    - warped_point: Coordinates of the index finger tip in the warped image.\n",
        "    - imgOverlay: Overlay image to be marked.\n",
        "\n",
        "    Returns:\n",
        "    - imgOverlay: Overlay image with marked polygons.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if isinstance(warped_point, list):\n",
        "        check = []\n",
        "        for warp_point in warped_point:\n",
        "            for polygon, name in polygons:\n",
        "                polygon_np = np.array(polygon, np.int32).reshape((-1, 1, 2))\n",
        "                result = cv2.pointPolygonTest(polygon_np, warp_point, False)\n",
        "                if result >= 0:\n",
        "                    cv2.polylines(imgOverlay, [np.array(polygon)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "                    cv2.fillPoly(imgOverlay, [np.array(polygon)], (0, 255, 0))\n",
        "                    cvzone.putTextRect(imgOverlay, name, polygon[0], scale=1, thickness=1)\n",
        "                    # cvzone.putTextRect(imgOverlay, name, (0, 100), scale=8, thickness=5)\n",
        "                    check.append(name)\n",
        "        if len(check) == 2:\n",
        "            cv2.line(imgOverlay, warped_point[0], warped_point[1], (0, 255, 0), 10)\n",
        "            for flight_time in flight_time_list:\n",
        "                if check[0] in flight_time and check[1] in flight_time:\n",
        "                    cvzone.putTextRect(imgOverlay, flight_time[1] + \" to \" + flight_time[0], (0, 100), scale=8,\n",
        "                                       thickness=5)\n",
        "                    cvzone.putTextRect(imgOverlay, flight_time[2], (0, 200), scale=8, thickness=5)\n",
        "    else:\n",
        "        # loop through all the countries\n",
        "        for polygon, name in polygons:\n",
        "            polygon_np = np.array(polygon, np.int32).reshape((-1, 1, 2))\n",
        "            result = cv2.pointPolygonTest(polygon_np, warped_point, False)\n",
        "            if result >= 0:\n",
        "                cv2.polylines(imgOverlay, [np.array(polygon)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
        "                cv2.fillPoly(imgOverlay, [np.array(polygon)], (0, 255, 0))\n",
        "                cvzone.putTextRect(imgOverlay, name, polygon[0], scale=1, thickness=1)\n",
        "                cvzone.putTextRect(imgOverlay, name, (0, 100), scale=8, thickness=5)\n",
        "\n",
        "    return imgOverlay\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the webcam\n",
        "    success, img = cap.read()\n",
        "    imgWarped, matrix = warp_image(img, map_points)\n",
        "    imgOutput = img.copy()\n",
        "\n",
        "    # Find the hand and its landmarks\n",
        "    warped_point = get_finger_location(img,imgWarped)\n",
        "\n",
        "    h, w, _ = imgWarped.shape\n",
        "    imgOverlay = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "\n",
        "    if warped_point:\n",
        "        imgOverlay = create_overlay_image(polygons, warped_point, imgOverlay)\n",
        "        imgOutput = inverse_warp_image(img, imgOverlay, map_points)\n",
        "\n",
        "\n",
        "    # imgStacked = cvzone.stackImages([img, imgWarped,imgOutput,imgOverlay], 2, 0.3)\n",
        "    # cv2.imshow(\"Stacked Image\", imgStacked)\n",
        "\n",
        "    # cv2.imshow(\"Original Image\", img)\n",
        "    # cv2.imshow(\"Warped Image\", imgWarped)\n",
        "    cv2.imshow(\"Output Image\", imgOutput)\n",
        "\n",
        "    key = cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "GwjGlARNAtgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}